{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2a91f8c",
   "metadata": {},
   "source": [
    "#### Trains our transformer model on the tokenized data\n",
    "\n",
    "1. Loads our token sequences and vocabulary \n",
    "2. Build Transformer model (probably going to use Pytorch but we will look into what)\n",
    "3. Train on tokens [:-1] -> [tokens [1:]]\n",
    "4. Save checkpoints and training logs\n",
    "\n",
    "\n",
    "P.S This is subject to lots of change on how we prepare the model I think we will probably be training on multiple datasets and then freezing at different points\n",
    "i.e train first on the accompaniment dataset so it understands general structure and how accompaniment works, then train on dataset with melodies as well so it gets how \n",
    "to play and be reactive based on the melody (we also need to add in a lot of noise and personal data for this part since we will not be perfect soloist like in the jazz\n",
    "songs and MIDI from a Database)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65e5213",
   "metadata": {},
   "source": [
    "Load the token sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fbe845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6eb45ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = Path.cwd().parent\n",
    "remi_segments_path = project_root / \"remi_segments.jsonl\"\n",
    "vocab_path = project_root / \"vocab.json\"\n",
    "\n",
    "# Load vocab\n",
    "with open(vocab_path, \"r\") as f:\n",
    "    vocab = json.load(f)\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# Load token sequences\n",
    "token_sequences = []\n",
    "with open(remi_segments_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        record = json.loads(line)\n",
    "        token_sequences.append(record[\"tokens\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5400224a",
   "metadata": {},
   "source": [
    "Encode the tokens as integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a76ccce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(tokens):\n",
    "    return [vocab.get(t, vocab[\"<UNK>\"]) for t in tokens]\n",
    "\n",
    "encoded_sequences = [encode(seq) for seq in token_sequences]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee62314c",
   "metadata": {},
   "source": [
    "Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1063b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TokenDataset(Dataset):\n",
    "    def __init__(self, sequences, seq_len=512):\n",
    "        self.samples = []\n",
    "        for seq in sequences:\n",
    "            # Chop long sequences into chunks\n",
    "            for i in range(0, len(seq) - seq_len):\n",
    "                self.samples.append((\n",
    "                    seq[i:i+seq_len],\n",
    "                    seq[i+1:i+seq_len+1]\n",
    "                ))\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.samples[idx]\n",
    "        return torch.tensor(x), torch.tensor(y)\n",
    "\n",
    "seq_len = 128  # or 512, depending on your GPU\n",
    "dataset = TokenDataset(encoded_sequences, seq_len=seq_len)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82867d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d61861f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rentmtl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
